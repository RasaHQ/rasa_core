
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Training and Policies</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/banner.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="Debugging" href="../debugging/" />
    <link rel="prev" title="Fallback Actions" href="../fallbacks/" />

<!-- Google Tag Manager -->
<script> 
  type="opt-in" data-name="gtm">(function(w, d, s, l, i) {
        w[l] = w[l] || [];
        w[l].push({
            'gtm.start': new Date().getTime(),
            event: 'gtm.js'
        });
        var f = d.getElementsByTagName(s)[0],
            j = d.createElement(s),
            dl = l != 'dataLayer' ? '&l=' + l : '';
        j.async = true;
        j.src =
            'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
        f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-MMHSZCS');
</script>
<!-- End Google Tag Manager -->
   
    
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />
  <meta itemprop="image" content="https://rasa.com/assets/img/facebook-og.png">
  <meta property="og:title" content="Training and Policies" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://rasa.com/assets/img/facebook-og.png" />
  <meta property="og:url" content="https://rasa.com/docs/core/policies" />
  
    <meta name="description" content="Understanding Rasa Core Policies" />
    <meta itemprop="description" content="Understanding Rasa Core Policies">
    <meta name="twitter:description" content="Understanding Rasa Core Policies" />
    <meta property="og:description" content="Understanding Rasa Core Policies" />
  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Rasa_HQ">
  <meta name="twitter:title" content="Training and Policies">
  <meta name="twitter:creator" content="@Rasa_HQ">
  <meta name="twitter:image" content="https://rasa.com/assets/img/facebook-og.png">
    
  <link rel="stylesheet" href="../_static/xq-light.css" type="text/css" />
  <link rel="stylesheet" href="../_static/fontawesome/css/fontawesome-all.css" type="text/css" />
  <script defer type="text/javascript" src="../_static/config.js"></script>
  <script defer type="text/javascript" src="../_static/klaro.js"></script>
  <script type="text/javascript" src="https://storage.googleapis.com/docs-theme/clipboard.min.js"></script>
  
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" /> 
  

  </head><body>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MMHSZCS" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<div class="nav-top">
  <div class="nav-container">
    <a href="/docs" class="brand-link">
        <h1 class="brand">
            <img src="../_static/rasa_logo.svg" width="80px" height="40px" title="Rasa logo" alt="Rasa logo">
        </h1>
        <span class="logo extension">docs</span>
    </a>
    
    <ul class="nav">
      <input type="text" class="search" placeholder="Search">
      
        
          <li><a href=/docs/getting-started/>Getting Started</a></li>
        
      
        
          <li><a href=/docs/nlu/>NLU</a></li>
        
      
        
          <li class="active"><a href=/docs/core/>Core</a></li>
        
      
        
          <li><a href=/docs/platform/>Platform</a></li>
        
      
      
      <li>
        <a href="https://forum.rasa.com" target="_blank"><button class="button btn-ghost btn-small">Join Community</button></a>
      </li>
      
    </ul>
  </div>
</div>

  <div class="sidebar-extended"></div>
  <div class="document">
    
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart/">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation/">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../architecture/">High-Level Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../connectors/">Chat &amp; Voice platforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../customactions/">Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../slots/">Using Slots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../slotfilling/">Slot Filling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../responses/">Bot Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../interactive_learning/">Interactive Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fallbacks/">Fallback Actions</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training and Policies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debugging/">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluation/">Evaluating and Testing</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../domains/">Domain Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stories/">Story Data Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/slots_api/">Slot Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../server/">HTTP API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/agent/">Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/events/">Events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/tracker/">Dialogue State Tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/interpreter/">Interpreters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/policy/">Policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/featurizer/">Featurization</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migrations/">Migration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../brokers/">Event Brokers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker/">Using Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog/">Change Log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../support/">Getting Support</a></li>
</ul>

<div class="versions">
    <p class="caption">Versions</p>
    <div class="versions-content">
      <div>
        <span class="current-version">
          viewing: 0.11.7
        </span>
      </div>
      <div class="other-versions">
          <p>tags</p>
          <div class="dropdown-content">
              <a href="../../0.11.7/policies/">0.11.7</a>
              <a href="../../0.11.6/policies/">0.11.6</a>
              <a href="../../0.11.5/policies/">0.11.5</a>
              <a href="../../0.11.4/policies/">0.11.4</a>
              <a href="../../0.11.3/policies/">0.11.3</a>
              <a href="../../0.11.2/policies/">0.11.2</a>
              <a href="../../0.11.1/policies/">0.11.1</a>
              <a href="../../0.11.0/policies/">0.11.0</a>
              <a href="../../0.10.4/policies/">0.10.4</a>
              <a href="../../0.9.8/policies/">0.9.8</a>
              <a href="../../0.8.6/policies/">0.8.6</a>
              <a href="../../0.7.9/policies/">0.7.9</a>
              <a href="../../0.6.9/policies/">0.6.9</a>
          </div>
          <p>branches</p>
          <div class="dropdown-content">
              <a href="../../master/policies/">master</a>
          </div>
      </div>
    </div>
</div>


        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  





<div class="section" id="training-and-policies">
<span id="policies"></span><h1>Training and Policies<a class="headerlink" href="#training-and-policies" title="Permalink to this headline">¶</a></h1>
<div class="section" id="training">
<h2>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h2>
<p>Rasa Core works by creating training data from your stories and
training a model on that data.</p>
<p>You can run training from the command line like in the <a class="reference internal" href="../quickstart/#quickstart"><span class="std std-ref">Quickstart</span></a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m rasa_core.train -d domain.yml -s data/stories.md -o models/current/dialogue --epochs <span class="m">200</span>
</pre></div>
</div>
<p>Or by creating an agent and running the train method yourself:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">rasa_core.agent</span> <span class="kn">import</span> <span class="n">Agent</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="s2">&quot;stories.md&quot;</span><span class="p">)</span>
<span class="n">agent</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="data-augmentation">
<h3>Data Augmentation<a class="headerlink" href="#data-augmentation" title="Permalink to this headline">¶</a></h3>
<p>By default, Rasa Core will create longer stories by randomly glueing together
the ones in your stories file. This is because if you have stories like:</p>
<div class="highlight-story notranslate"><div class="highlight"><pre><span></span># thanks
* thankyou
   - utter_youarewelcome

# bye
* goodbye
   - utter_goodbye
</pre></div>
</div>
<p>You actually want to teach your policy to <strong>ignore</strong> the dialogue history
when it isn’t relevant and just respond with the same action no matter what happened
before.</p>
<p>You can alter this behaviour with the <code class="docutils literal notranslate"><span class="pre">--augmentation</span></code> flag. <code class="docutils literal notranslate"><span class="pre">--augmentation</span> <span class="pre">0</span></code>
disables this behavior.</p>
<p>In python, you can pass the <code class="docutils literal notranslate"><span class="pre">augmentation_factor</span></code> argument to the <code class="docutils literal notranslate"><span class="pre">Agent.load_data</span></code> method.</p>
</div>
<div class="section" id="max-history">
<h3>Max History<a class="headerlink" href="#max-history" title="Permalink to this headline">¶</a></h3>
<p>One important hyperparameter for Rasa Core policies is the <code class="docutils literal notranslate"><span class="pre">max_history</span></code>.
This controls how much dialogue history the model looks at to decide which action
to take next.</p>
<p>You can set the <code class="docutils literal notranslate"><span class="pre">max_history</span></code> using the training script’s <code class="docutils literal notranslate"><span class="pre">--history</span></code> flag or
by passing it to your policy’s <code class="xref py py-class docutils literal notranslate"><span class="pre">Featurizer</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Only the <code class="docutils literal notranslate"><span class="pre">MaxHistoryTrackerFeaturizer</span></code> uses a max history, whereas the
<code class="docutils literal notranslate"><span class="pre">FullDialogueTrackerFeaturizer</span></code> always looks at the full conversation history.</p>
</div>
<p>As an example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">out_of_scope</span></code> intent which describes off-topic
user messages. If your bot sees this intent multiple times in a row, you might want to
tell the user what you <cite>can</cite> help them with. So your story might look like this:</p>
<div class="highlight-story notranslate"><div class="highlight"><pre><span></span>* out_of_scope
   - utter_default
* out_of_scope
   - utter_default
* out_of_scope
   - utter_help_message
</pre></div>
</div>
<p>For Rasa Core to learn this pattern, the <code class="docutils literal notranslate"><span class="pre">max_history</span></code> has to be <cite>at least</cite> <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p>
<p>If you increase your <code class="docutils literal notranslate"><span class="pre">max_history</span></code>, your model will become bigger and training will take longer.
If you have some information that should affect the dialogue very far into the future,
you should store it as a slot. Slot information is always available for every featurizer.</p>
</div>
<div class="section" id="training-script-options">
<h3>Training Script Options<a class="headerlink" href="#training-script-options" title="Permalink to this headline">¶</a></h3>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>usage: train.py [-h] (-s STORIES | --url URL | --core CORE) [-o OUT]
                [-d DOMAIN] [-u NLU] [--history HISTORY] [--epochs EPOCHS]
                [--validation_split VALIDATION_SPLIT]
                [--batch_size BATCH_SIZE] [--online] [--finetune]
                [--augmentation AUGMENTATION] [--debug_plots] [--dump_stories]
                [--endpoints ENDPOINTS] [--nlu_threshold NLU_THRESHOLD]
                [--core_threshold CORE_THRESHOLD]
                [--fallback_action_name FALLBACK_ACTION_NAME] [-v] [-vv]
                [--quiet]

trains a dialogue model

optional arguments:
  -h, --help            show this help message and exit
  -s STORIES, --stories STORIES
                        file or folder containing the training stories
  --url URL             If supplied, downloads a story file from a URL and
                        trains on it. Fetches the data by sending a GET
                        request to the supplied URL.
  --core CORE           path to load a pre-trained model instead of training
                        (for online mode only)
  -o OUT, --out OUT     directory to persist the trained model in
  -d DOMAIN, --domain DOMAIN
                        domain specification yaml file
  -u NLU, --nlu NLU     trained nlu model
  --history HISTORY     max history to use of a story
  --epochs EPOCHS       number of epochs to train the model
  --validation_split VALIDATION_SPLIT
                        Percentage of training samples used for validation,
                        0.1 by default
  --batch_size BATCH_SIZE
                        number of training samples to put into one training
                        batch
  --online              enable online training
  --finetune            retrain the model immediately based on feedback.
  --augmentation AUGMENTATION
                        how much data augmentation to use during training
  --debug_plots         If enabled, will create plots showing checkpoints and
                        their connections between story blocks in a file
                        called `story_blocks_connections.pdf`.
  --dump_stories        If enabled, save flattened stories to a file
  --endpoints ENDPOINTS
                        Configuration file for the connectors as a yml file
  --nlu_threshold NLU_THRESHOLD
                        If NLU prediction confidence is below threshold,
                        fallback will get triggered.
  --core_threshold CORE_THRESHOLD
                        If Core action prediction confidence is below the
                        threshold a fallback action will get triggered
  --fallback_action_name FALLBACK_ACTION_NAME
                        When a fallback is triggered (e.g. because the ML
                        prediction is of low confidence) this is the name of
                        tje action that will get triggered instead.
  -v, --verbose         Be verbose. Sets logging level to INFO
  -vv, --debug          Print lots of debugging statements. Sets logging level
                        to DEBUG
  --quiet               Be quiet! Sets logging level to WARNING
</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h2>Policies<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="../api/policy/#rasa_core.policies.Policy" title="rasa_core.policies.Policy"><code class="xref py py-class docutils literal notranslate"><span class="pre">rasa_core.policies.Policy</span></code></a> class decides which action to take
at every step in the conversation.</p>
<p>There are different policies to choose from, and you can include multiple policies
in a single <code class="xref py py-class docutils literal notranslate"><span class="pre">Agent</span></code>. At every turn, the policy which predicts the
next action with the highest confidence will be used.
You can pass a list of policies when you create an agent:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">rasa_core.policies.memoization</span> <span class="kn">import</span> <span class="n">MemoizationPolicy</span>
<span class="kn">from</span> <span class="nn">rasa_core.policies.keras_policy</span> <span class="kn">import</span> <span class="n">KerasPolicy</span>
<span class="kn">from</span> <span class="nn">rasa_core.agent</span> <span class="kn">import</span> <span class="n">Agent</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="s2">&quot;domain.yml&quot;</span><span class="p">,</span>
               <span class="n">policies</span><span class="o">=</span><span class="p">[</span><span class="n">MemoizationPolicy</span><span class="p">(),</span> <span class="n">KerasPolicy</span><span class="p">()])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">By default, Rasa Core uses the <code class="xref py py-class docutils literal notranslate"><span class="pre">KerasPolicy</span></code> in combination with
the <code class="xref py py-class docutils literal notranslate"><span class="pre">MemoizationPolicy</span></code>.</p>
</div>
<div class="section" id="memoization-policy">
<h3>Memoization Policy<a class="headerlink" href="#memoization-policy" title="Permalink to this headline">¶</a></h3>
<p>The <code class="xref py py-class docutils literal notranslate"><span class="pre">MemoizationPolicy</span></code> just memorizes the conversations in your training data.
It predicts the next action with confidence <code class="docutils literal notranslate"><span class="pre">1.0</span></code> if this exact conversation exists in the
training data, otherwise it predicts <code class="docutils literal notranslate"><span class="pre">None</span></code> with confidence <code class="docutils literal notranslate"><span class="pre">0.0</span></code>.</p>
</div>
<div class="section" id="keras-policy">
<h3>Keras Policy<a class="headerlink" href="#keras-policy" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">KerasPolicy</span></code> uses a neural network implemented in <a class="reference external" href="http://keras.io">Keras</a> to
select the next action.
The default architecture is based on an LSTM, but you can override the
<code class="docutils literal notranslate"><span class="pre">KerasPolicy.model_architecture</span></code> method to implement your own architecture.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">model_architecture</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">input_shape</span><span class="p">,</span>  <span class="c1"># type: Tuple[int, int]</span>
            <span class="n">output_shape</span>  <span class="c1"># type: Tuple[int, Optional[int]]</span>
    <span class="p">):</span>
        <span class="c1"># type: (...) -&gt; tf.keras.models.Sequential</span>
        <span class="sd">&quot;&quot;&quot;Build a keras model and return a compiled model.&quot;&quot;&quot;</span>

        <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
        <span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">import</span> \
            <span class="n">Masking</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">TimeDistributed</span><span class="p">,</span> <span class="n">Activation</span>

        <span class="c1"># Build Model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

        <span class="c1"># the shape of the y vector of the labels,</span>
        <span class="c1"># determines which output from rnn will be used</span>
        <span class="c1"># to calculate the loss</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># y is (num examples, num features) so</span>
            <span class="c1"># only the last output from the rnn is used to</span>
            <span class="c1"># calculate the loss</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Masking</span><span class="p">(</span><span class="n">mask_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">))</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># y is (num examples, max_dialogue_len, num features) so</span>
            <span class="c1"># all the outputs from the rnn are used to</span>
            <span class="c1"># calculate the loss, therefore a sequence is returned and</span>
            <span class="c1"># time distributed layer is used</span>

            <span class="c1"># the first value in input_shape is max dialogue_len,</span>
            <span class="c1"># it is set to None, to allow dynamic_rnn creation</span>
            <span class="c1"># during prediction</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Masking</span><span class="p">(</span><span class="n">mask_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                              <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot construct the model because&quot;</span>
                             <span class="s2">&quot;length of output_shape = </span><span class="si">{}</span><span class="s2"> &quot;</span>
                             <span class="s2">&quot;should be 1 or 2.&quot;</span>
                             <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)))</span>

        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
                      <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
                      <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>and the training is run here:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
              <span class="n">training_trackers</span><span class="p">,</span>  <span class="c1"># type: List[DialogueStateTracker]</span>
              <span class="n">domain</span><span class="p">,</span>  <span class="c1"># type: Domain</span>
              <span class="o">**</span><span class="n">kwargs</span>  <span class="c1"># type: Any</span>
              <span class="p">):</span>
        <span class="c1"># type: (...) -&gt; Dict[Text: Any]</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;rnn_size&#39;</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Parameter `rnn_size` is updated with </span><span class="si">{}</span><span class="s2">&quot;</span>
                         <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;rnn_size&#39;</span><span class="p">)))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;rnn_size&#39;</span><span class="p">)</span>

        <span class="n">training_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">featurize_for_training</span><span class="p">(</span><span class="n">training_trackers</span><span class="p">,</span>
                                                    <span class="n">domain</span><span class="p">,</span>
                                                    <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># noinspection PyPep8Naming</span>
        <span class="n">shuffled_X</span><span class="p">,</span> <span class="n">shuffled_y</span> <span class="o">=</span> <span class="n">training_data</span><span class="o">.</span><span class="n">shuffled_X_y</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_architecture</span><span class="p">(</span><span class="n">shuffled_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                                         <span class="n">shuffled_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>

                <span class="n">validation_split</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;validation_split&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Fitting model with </span><span class="si">{}</span><span class="s2"> total samples and a validation &quot;</span>
                            <span class="s2">&quot;split of </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">training_data</span><span class="o">.</span><span class="n">num_examples</span><span class="p">(),</span>
                                                 <span class="n">validation_split</span><span class="p">))</span>
                <span class="c1"># filter out kwargs that cannot be passed to fit</span>
                <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_valid_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">shuffled_X</span><span class="p">,</span> <span class="n">shuffled_y</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
                <span class="c1"># the default parameter for epochs in keras fit is 1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;epochs&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Done fitting keras policy model&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can implement the model of your choice by overriding these methods,
or initialize <code class="docutils literal notranslate"><span class="pre">KerasPolicy</span></code> with pre-defined <code class="docutils literal notranslate"><span class="pre">keras</span> <span class="pre">model</span></code>.</p>
</div>
</div>
<div class="section" id="embedding-policy">
<span id="id2"></span><h2>Embedding policy<a class="headerlink" href="#embedding-policy" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt>This policy has a pre-defined architecture, which comprises the following steps:</dt>
<dd><ul class="first last simple">
<li>apply dense layers to create embeddings for user intents, entities and system actions including previous actions and slots;</li>
<li>use the embeddings of previous user inputs as a user memory and embeddings of previous system actions as a system memory;</li>
<li>concatenate user input, previous system action and slots embeddings for current time into an input vector to rnn;</li>
<li>using user and previous system action embeddings from the input vector, calculate attention probabilities over the user and system memories
(for system memory, this policy uses <a class="reference external" href="https://arxiv.org/abs/1410.5401">NTM mechanism</a> with attention by location);</li>
<li>sum the user embedding and user attention vector and feed it and the embeddings of the slots as an input to an LSTM cell;</li>
<li>apply a dense layer to the output of the LSTM to get a raw recurrent embedding of a dialogue;</li>
<li>sum this raw recurrent embedding of a dialogue with system attention vector to create dialogue level embedding,
this step allows the algorithm to repeat previous system action by copying its embedding vector directly to the current time output;</li>
<li>weight previous LSTM states with system attention probabilities to get the previous action embedding, the policy is likely payed attention to;</li>
<li>if the similarity between this previous action embedding and current time dialogue embedding is high,
overwrite current LSTM state with the one from the time when this action happened;</li>
<li>for each LSTM time step, calculate the similarity between the dialogue embedding and embedded system actions.
This step is based on the starspace idea from: <a class="reference external" href="https://arxiv.org/abs/1709.03856">https://arxiv.org/abs/1709.03856</a>.</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This policy only works with <code class="docutils literal notranslate"><span class="pre">FullDialogueTrackerFeaturizer(state_featurizer)</span></code>.</p>
</div>
<p>It is recommended to use <code class="docutils literal notranslate"><span class="pre">state_featurizer=LabelTokenizerSingleStateFeaturizer(...)</span></code> (see <a class="reference internal" href="../api/featurizer/#featurization"><span class="std std-ref">Featurization</span></a> for details).</p>
<p><strong>Configuration</strong>:</p>
<blockquote>
<div><blockquote>
<div><p>Configuration parameters can be passed to <code class="docutils literal notranslate"><span class="pre">agent.train(...)</span></code> method.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Pass an appropriate <code class="docutils literal notranslate"><span class="pre">epochs</span></code> number to <code class="docutils literal notranslate"><span class="pre">agent.train(...)</span></code> method,
otherwise the policy will be trained only for <code class="docutils literal notranslate"><span class="pre">1</span></code> epoch. Since this is embedding based policy,
it requires a large number of epochs, which depends on the complexity of the training data and whether attention is used or not.</p>
</div>
<p>The main feature of this policy is an <strong>attention</strong> mechanism over previous user input and system actions.
<strong>Attention is turned on by default</strong>, in order to turn it off, configure the following parameters:</p>
<blockquote>
<div><ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">attn_before_rnn</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm will use attention mechanism over previous user input, default <code class="docutils literal notranslate"><span class="pre">true</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">attn_after_rnn</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm will use attention mechanism over previous system actions
and will be able to copy previously executed action together with LSTM’s hidden state from its history, default <code class="docutils literal notranslate"><span class="pre">true</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">sparse_attention</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> <code class="docutils literal notranslate"><span class="pre">sparsemax</span></code> will be used instead of <code class="docutils literal notranslate"><span class="pre">softmax</span></code> for attention probabilities, default <code class="docutils literal notranslate"><span class="pre">false</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">attn_shift_range</span></code> the range of allowed location-based attention shifts for system memory (<code class="docutils literal notranslate"><span class="pre">attn_after_rnn</span></code>), see <a class="reference external" href="https://arxiv.org/abs/1410.5401">https://arxiv.org/abs/1410.5401</a> for details;</li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Attention requires larger values of <code class="docutils literal notranslate"><span class="pre">epochs</span></code> and takes longer to train. But it can learn more complicated and nonlinear behaviour.</p>
</div>
<dl class="docutils">
<dt>The algorithm also has hyperparameters to control:</dt>
<dd><ul class="first last simple">
<li><dl class="first docutils">
<dt>neural network’s architecture:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_a</span></code> sets a list of hidden layers sizes before embedding layer for user inputs, the number of hidden layers is equal to the length of the list;</li>
<li><code class="docutils literal notranslate"><span class="pre">hidden_layers_sizes_b</span></code> sets a list of hidden layers sizes before embedding layer for system actions, the number of hidden layers is equal to the length of the list;</li>
<li><code class="docutils literal notranslate"><span class="pre">rnn_size</span></code> sets the number of units in the LSTM cell;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>training:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">layer_norm</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> layer normalization for lstm cell is turned on,  default <code class="docutils literal notranslate"><span class="pre">true</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">batch_size</span></code> sets the number of training examples in one forward/backward pass, the higher the batch size, the more memory space you’ll need;</li>
<li><code class="docutils literal notranslate"><span class="pre">epochs</span></code> sets the number of times the algorithm will see training data, where <code class="docutils literal notranslate"><span class="pre">one</span> <span class="pre">epoch</span></code> = one forward pass and one backward pass of all the training examples;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>embedding:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">embed_dim</span></code> sets the dimension of embedding space;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> controls how similar the algorithm should try to make embedding vectors for correct intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> controls maximum negative similarity for incorrect intents;</li>
<li><code class="docutils literal notranslate"><span class="pre">similarity_type</span></code> sets the type of the similarity, it should be either <code class="docutils literal notranslate"><span class="pre">cosine</span></code> or <code class="docutils literal notranslate"><span class="pre">inner</span></code>;</li>
<li><code class="docutils literal notranslate"><span class="pre">num_neg</span></code> sets the number of incorrect intent labels, the algorithm will minimize their similarity to the user input during training;</li>
<li><code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span></code> if <code class="docutils literal notranslate"><span class="pre">true</span></code> the algorithm only minimizes maximum similarity over incorrect intent labels;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>regularization:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">C2</span></code> sets the scale of L2 regularization</li>
<li><code class="docutils literal notranslate"><span class="pre">C_emb</span></code> sets the scale of how important is to minimize the maximum similarity between embeddings of different intent labels;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate_a</span></code> sets the dropout rate between hidden layers before embedding layer for user inputs;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate_b</span></code> sets the dropout rate between hidden layers before embedding layer for system actions;</li>
<li><code class="docutils literal notranslate"><span class="pre">droprate_rnn</span></code> sets the recurrent dropout rate on the LSTM hidden state <a class="reference external" href="https://arxiv.org/abs/1603.05118">https://arxiv.org/abs/1603.05118</a>;</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>train accuracy calculation:</dt>
<dd><ul class="first last">
<li><code class="docutils literal notranslate"><span class="pre">evaluate_every_num_epochs</span></code> sets how often to calculate train accuracy, small values may hurt performance;</li>
<li><code class="docutils literal notranslate"><span class="pre">evaluate_on_num_examples</span></code> how many examples to use for calculation of train accuracy, large values may hurt performance.</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Droprate should be between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">droprate=0.1</span></code> would drop out <code class="docutils literal notranslate"><span class="pre">10%</span></code> of input units</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For <code class="docutils literal notranslate"><span class="pre">cosine</span></code> similarity <code class="docutils literal notranslate"><span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> should be between <code class="docutils literal notranslate"><span class="pre">-1</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">There is an option to use linearly increasing batch size. The idea comes from <a class="reference external" href="https://arxiv.org/abs/1711.00489">https://arxiv.org/abs/1711.00489</a>.
In order to do it pass a list to <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">[8,</span> <span class="pre">32]</span></code> (default behaviour).
If constant <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is required, pass an <code class="docutils literal notranslate"><span class="pre">int</span></code>, e.g. <code class="docutils literal notranslate"><span class="pre">&quot;batch_size&quot;:</span> <span class="pre">8</span></code>.</p>
</div>
<p>These parameters can be passed to <code class="docutils literal notranslate"><span class="pre">Agent.train(...)</span></code> method.
The default values are defined in <code class="docutils literal notranslate"><span class="pre">EmbeddingPolicy.defaults</span></code>:</p>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1"># nn architecture</span>
        <span class="c1"># a list of hidden layers sizes before user embed layer</span>
        <span class="c1"># number of hidden layers is equal to the length of this list</span>
        <span class="s2">&quot;hidden_layers_sizes_a&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="c1"># a list of hidden layers sizes before bot embed layer</span>
        <span class="c1"># number of hidden layers is equal to the length of this list</span>
        <span class="s2">&quot;hidden_layers_sizes_b&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="c1"># number of units in rnn cell</span>
        <span class="s2">&quot;rnn_size&quot;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>

        <span class="c1"># training parameters</span>
        <span class="c1"># flag if to turn on layer normalization for lstm cell</span>
        <span class="s2">&quot;layer_norm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="c1"># initial and final batch sizes - batch size will be</span>
        <span class="c1"># linearly increased for each epoch</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
        <span class="c1"># number of epochs</span>
        <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>

        <span class="c1"># embedding parameters</span>
        <span class="c1"># dimension size of embedding vectors</span>
        <span class="s2">&quot;embed_dim&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
        <span class="c1"># how similar the algorithm should try</span>
        <span class="c1"># to make embedding vectors for correct actions</span>
        <span class="s2">&quot;mu_pos&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>  <span class="c1"># should be 0.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
        <span class="c1"># maximum negative similarity for incorrect actions</span>
        <span class="s2">&quot;mu_neg&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># should be -1.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
        <span class="c1"># the type of the similarity</span>
        <span class="s2">&quot;similarity_type&quot;</span><span class="p">:</span> <span class="s1">&#39;cosine&#39;</span><span class="p">,</span>  <span class="c1"># string &#39;cosine&#39; or &#39;inner&#39;</span>
        <span class="c1"># the number of incorrect actions, the algorithm will minimize</span>
        <span class="c1"># their similarity to the user input during training</span>
        <span class="s2">&quot;num_neg&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
        <span class="c1"># flag if minimize only maximum similarity over incorrect actions</span>
        <span class="s2">&quot;use_max_sim_neg&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># flag which loss function to use</span>

        <span class="c1"># regularization</span>
        <span class="c1"># the scale of L2 regularization</span>
        <span class="s2">&quot;C2&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
        <span class="c1"># the scale of how important is to minimize the maximum similarity</span>
        <span class="c1"># between embeddings of different actions</span>
        <span class="s2">&quot;C_emb&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="c1"># scale loss with inverse frequency of bot actions</span>
        <span class="s2">&quot;scale_loss_by_action_counts&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>

        <span class="c1"># dropout rate for user nn</span>
        <span class="s2">&quot;droprate_a&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="c1"># dropout rate for bot nn</span>
        <span class="s2">&quot;droprate_b&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="c1"># dropout rate for rnn</span>
        <span class="s2">&quot;droprate_rnn&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>

        <span class="c1"># attention parameters</span>
        <span class="c1"># flag to use attention over user input</span>
        <span class="c1"># as an input to rnn</span>
        <span class="s2">&quot;attn_before_rnn&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="c1"># flag to use attention over prev bot actions</span>
        <span class="c1"># and copy it to output bypassing rnn</span>
        <span class="s2">&quot;attn_after_rnn&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>

        <span class="c1"># flag to use `sparsemax` instead of `softmax` for attention</span>
        <span class="s2">&quot;sparse_attention&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># flag to use sparsemax for probs</span>
        <span class="c1"># the range of allowed location-based attention shifts</span>
        <span class="s2">&quot;attn_shift_range&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># if None, set to mean dialogue length / 2</span>

        <span class="c1"># visualization of accuracy</span>
        <span class="c1"># how often calculate train accuracy</span>
        <span class="s2">&quot;evaluate_every_num_epochs&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>  <span class="c1"># small values may hurt performance</span>
        <span class="c1"># how many examples to use for calculation of train accuracy</span>
        <span class="s2">&quot;evaluate_on_num_examples&quot;</span><span class="p">:</span> <span class="mi">100</span>  <span class="c1"># large values may hurt performance</span>
    <span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Parameter <code class="docutils literal notranslate"><span class="pre">mu_neg</span></code> is set to a negative value to mimic the original
starspace algorithm in the case <code class="docutils literal notranslate"><span class="pre">mu_neg</span> <span class="pre">=</span> <span class="pre">mu_pos</span></code> and <code class="docutils literal notranslate"><span class="pre">use_max_sim_neg</span> <span class="pre">=</span> <span class="pre">False</span></code>.
See <a class="reference external" href="https://arxiv.org/abs/1709.03856">starspace paper</a> for details.</p>
</div>
</div></blockquote>
</div>
<div class="section" id="have-questions-or-feedback">
<h2>Have questions or feedback?<a class="headerlink" href="#have-questions-or-feedback" title="Permalink to this headline">¶</a></h2>
<p>We have a very active support community on <a class="reference external" href="https://forum.rasa.com">Rasa Community Forum</a>
that is happy to help you with your questions. If you have any feedback for us or a specific
suggestion for improving the docs, feel free to share it by creating an issue on Rasa Core
<a class="reference external" href="https://github.com/RasaHQ/rasa_core/issues">GitHub repository</a>.</p>
<div id="livechat">
   <!--Start of Tawk.to Script-->
   <script type="text/javascript">
      var Tawk_API=Tawk_API||{}, Tawk_LoadStart=new Date();
      (function(){
      var s1=document.createElement("script"),s0=document.getElementsByTagName("script")[0];
      s1.async=true;
      s1.src='https://embed.tawk.to/5b85a455afc2c34e96e7fedd/default';
      s1.charset='UTF-8';
      s1.setAttribute('crossorigin','*');
      s0.parentNode.insertBefore(s1,s0);
      })();
   </script>
   <!--End of Tawk.to Script-->
</div></div>
</div>


	    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script> 
	    <script type="text/javascript"> docsearch({ 
	     apiKey: '1f9e0efb89e98543f6613a60f847b176', 
	     indexName: 'rasa', 
	     inputSelector: 'body > div.nav-top > .nav-container > .nav > input', 
	     debug: false // Set debug to true if you want to inspect the dropdown 
	    }); 
	    </script> 
          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2018, Rasa Technologies GmbH | <a href="https://rasa.com/imprint/" target="_blank">Imprint</a> | <a href="https://rasa.com/privacy-policy/" target="_blank">Privacy Policy</a> 
      

    </div>

    

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async type="opt-in" data-name="googleanalytics" data-type="text/javascript" data-src="https://www.googletagmanager.com/gtag/js?id=UA-87333416-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());
    gtag('config', 'UA-87333416-1', {
      'anonymize_ip': true,
    });
  </script>
  <script type="text/javascript">
    var clipboard = new ClipboardJS('.copyable');
    clipboard.on('success', function(e) {
      gtag('event', e.action, {
        'event_category': 'code',
        'event_label': e.text
      });
      const id = e.text.slice(0,3);
      document.getElementById(id).classList.add('visible');
      setTimeout(function(){ 
        document.getElementById(id).classList.remove('visible');}, 
        800
      );
    });
    clipboard.on('error', function(e) {
      console.log(e);
    });
  </script>
  
  <!-- onsite anchor fix (otherwise anchors scroll to far) -->
  <script>
    /* Adapted from https://stackoverflow.com/a/13067009/1906073 */
    (function(document, history, location) {
      var HISTORY_SUPPORT = !!(history && history.pushState);

      var anchorScrolls = {
        ANCHOR_REGEX: /^#[^ ]+$/,
        OFFSET_HEIGHT_PX: 66,

        /**
         * Establish events, and fix initial scroll position if a hash is provided.
         */
        init: function() {
          this.scrollToCurrent();
          $(window).on('hashchange', $.proxy(this, 'scrollToCurrent'));
          $('body').on('click', 'a', $.proxy(this, 'delegateAnchors'));
        },

        /**
         * Return the offset amount to deduct from the normal scroll position.
         * Modify as appropriate to allow for dynamic calculations
         */
        getFixedOffset: function() {
          return this.OFFSET_HEIGHT_PX;
        },

        /**
         * If the provided href is an anchor which resolves to an element on the
         * page, scroll to it.
         * @param  {String} href
         * @return {Boolean} - Was the href an anchor.
         */
        scrollIfAnchor: function(href, pushToHistory) {
          var match, anchorOffset;

          if(!this.ANCHOR_REGEX.test(href)) {
            return false;
          }

          match = document.getElementById(href.slice(1));

          if(match) {
            anchorOffset = $(match).offset().top - this.getFixedOffset();
            $('html, body').animate({ scrollTop: anchorOffset});

            // Add the state to history as-per normal anchor links
            if(HISTORY_SUPPORT && pushToHistory) {
              history.pushState({}, document.title, location.pathname + href);
            }
          }

          return !!match;
        },
        
        /**
         * Attempt to scroll to the current location's hash.
         */
        scrollToCurrent: function(e) { 
          if(this.scrollIfAnchor(window.location.hash) && e) {
            e.preventDefault();
          }
        },

        /**
         * If the click event's target was an anchor, fix the scroll position.
         */
        delegateAnchors: function(e) {
          var elem = e.target;

          if(this.scrollIfAnchor(elem.getAttribute('href'), true)) {
            e.preventDefault();
          }
        }
      };

      $(document).ready($.proxy(anchorScrolls, 'init'));
    })(window.document, window.history, window.location);

  </script>
  </body>
</html>